Copyright © 2015. Siteworx, LLC. All Rights Reserved.

Welcome to the last base chapter of the Siteworx Developer Focus Elasticsearch series.  Join me, Jim, Senior Developer at Siteworx, in finishing up our introduction to Elasticsearch.  While we are going out with a bang, don't worry, this is far from goodbye.

Let's recap the entire series, shall we?  We created our index, type, and fields using a variety of field types for our Generation 1 Pokemon dataset.  We learned how to index individual pokemon as well as bulk index all of them.  We ran both simple and complex queries, and combined them using the Bool query.  We learned how to paginate and sort our results.  I feel like there is one more major feature to go over to round out this series, and that is

Chapter 12: Aggregations (Facets)

In this chapter, we will learn about the potential uses of aggregations, which were previously called facets, in Elasticsearch.  We will test out some of the core aggregations from each the two major types: Metrics and Bucket Aggregations.  We will also learn how to get aggregation information for a query without getting actual search results, which can speed up the request.

The setup files for this chapter are linked in the video description.  If you need help with the setup please check out the Chapter 3 video.  While organizing this chapter, I realized that we don't really have any fields that we could run metrics aggregations on, so I've added a height and weight field to the index setup, and added the height and weight of each pokemon to the bulk json file.  Besides that, everything else is the same: run setup.sh, which drops the index, recreates it, and bulk indexes the pokemon.  Once that's done, check the head plugin's overview to verify your counts and index metadata.  Make sure you see height and weight as type: float in the index metadata.  Once everything looks good, we're ready to begin.

So, what is an aggregation?  It is more or less a set of analytic data over a set of documents, and those documents are usually your search query results.  For our purposes, we will use aggregations to display data about our results based on different fields, such as "calculate the average height of the pokemon in my result set" or "show me all of the types in my result set, and how many results use each type".  Think of an aggregation as a summary of data about our entire result set, even if we only get the first 10 as actual results.

First let's check out Metrics Aggregations.  These aggregations compute metrics based on values in our search results.  They are usually run on numeric fields and output numeric values.  I had to add the height and weight of each Pokemon to better demo metrics aggregations.  Examples would be obtaining the largest, smallest, or average weight or height in our results.  Let's start by using the Stats Aggregation to get a variety of that information in one shot.

Since this is more about aggregations than the actual querying, I am going to make my example query something simple: a match query for the keywords psychic flying.  As expected, I get all pokemon with mention of either psychic or flying.  And you'll see each now has a weight in pounds, and height in inches.  Now I am going to add aggregations to my request by adding the aggs property to my JSON.  Under that, I add the aggregations I'd like by selecting the name I want to use to represent this aggregation.  I am going to name this one "weight_stats".  Inside of that, I set the actual aggregation to use, which is "stats" and inside that I tell Elasticsearch which field to give me stats on.  Based on the name I selected, I am going to point this at "weight".  And once I run the query, I can hide my hits so I can see the stats that return: count which is the number of weight values in the results, min which is the minimum weight in the results, max the maximum weight, avg the average weight, and sum is the total of all of the weights combined.  Remember that these stats are calculated based on the results of my query, not the entire dataset.  Each of these can be run individually like so: I can change "stats" to "min" and I get only the min value.  But we might as well see all of them using stats.  Let's also do the same for height since I went through the effort of adding it.  And now we can see both stats.

While stats covers most of the basic metrics aggregations, I also wanted to specifically look at Value Count.  While the rest of the metric aggregations can only be run on numeric fields, value count can be run on non-numeric.  So I am going to run it on the type field and you'll see the total number of types found in the result set.  Since many pokemon have multiple types, we get a higher number than our result total.  Please understand that this is not the number of unique types in the results, it is just the number of values found for that field.  It's not the most useful information, but for fields that are strings, we are better off using Bucket Aggregations.

Before I move onto Bucket Aggregations, I'm going to set my size to 0 so I don't have to be constantly closing the hits list to see the aggregation results.  This can also speed up our response time, as Elasticsearch doesn't have to give us actual results.

Bucket Aggregations get their name from the process that Elasticsearch uses to create them.  Basically, each one is like a bucket that it "drops" documents into if they match the criteria set for the aggregation.  It also counts the number of documents that fall into each bucket.  Rather than try to explain the functionality further, let's jump into examples to help us understand them.

The first and most commonly used bucket aggregation, at least in my past experience, is the Terms Aggregation.  This creates a bucket for each value of a specific field found in the results, and returns the value and the count in the response.  Our best example is the type field.  So let's change our agg name to "types" and make it a "terms" aggregation, and run our query again.  Now you'll see the list of all the types found in our query results, and the number of pokemon with that type set.  You'll notice that they're all lowercase.  This is because we are running it on the tokenized version of type.  If we change this to type.raw, we will get all of the exact values and their counts.  It is always ideal to use the exact value if one is available.  Luckily, type has one, but another field, such as how_to_find.method, does not, and will lead to some issues.  Notice how when I run the aggregation on that field, both time and capsule are separate values.  Since how_to_find.method doesn't have a raw field, we will never be able to get Time Capsule together in a value.  As an exercise, try changing how_to_find.method to be a multifield with a raw value and reindex and then try this query.  Let's go back to type.raw and check out this property that is returned to us: sum_other_doc_count.  When there's a value here, it means there were other type values found, but by default this aggregation only shows the top 10 by count.  We can change this by adding size: 0 to the query to tell Elasticsearch to give us all of the types back, not just the first 10.  And now we see all of them, even those last 3.  Finally, we can see that the default order of these is the doc_count, from highest to lowest.  We can change it to order them alphabetically by name, like so, or by the count, but ascending instead of descending, like so.  A lot of search apps or sites use aggregations like this one to tell the end user how many documents there are for each value in a field, and allow the user to select one and it will add the term to the query.  For example, if our pokedex had a front end, and I clicked on Dragon, it would rerun my query with a bool query and add a term query to the filter clauses, like so.  Let me remove my size 0 so you can see the 1 result, which matches the doc count we saw in our previous query's terms aggregation.  And now our new query has its own terms aggregation, which is much smaller since we only have 1 result.

Even though numeric fields are used for metrics aggregations, that doesn't mean we can't use them in Bucket aggregations.  The Histogram aggregation is a Bucket aggregation for use on numeric fields that creates its buckets of a fixed size based on the interval set in the query.  Let me reset my query back to psychic flying with the size of 0.  Now I am going to run a histogram aggregation on height with an interval of 12 inches.  Now what you'll see here is a fixed range for each bucket: the first says there are 4 pokemon between 12 and 24.  The first interval returned is the lowest number bucket that has a doc count of at least 1.  So if we had a pokemon that was 6 inches, we would see a key of 0 first.  Moving on, the second says there's 3 between 24 and 36, and so on.  Note you'll see a lot of intervals with 0 count, just so we can finally reach the highest count.  We can remove these 0 count bucket entries by adding min_doc_count to our request.  Now we only get intervals that have results.

Say we wanted multiple, different sized buckets, instead of having them set at fixed values following an interval.  The Range Aggregation allows us to do that.  Let's set up a range aggregation on weight that has these 3 buckets: 0 - 25 lbs, 25 to 100 lbs, and over 100 pounds.  Oops, looks like I forgot to rename my aggregation for my height histogram, but that goes to show you that it's just a name for our own reference.  Now our result set shows 5 between 0 and 25, 9 between 25 and 100, and 18 over 100 pounds.  An important note to mention is that the range includes the "to", but excludes the "from".  So a pokemon that is exactly 100 pounds would be in the over 100 count, but not the 25 through 100 one.  I can also run a range query on date fields, such as our date_captured field.  Here I am setting 3 date ranges: everything before april 1, everything from april 1 to august 1, and everything after august 1, and you'll see the the counts for each once I run it.

Now, what if we wanted the date ranges to be dynamic?  Say instead of setting static dates for each range, that we wanted to get counts for all dates from over a year ago, between a 6 months and a year ago, and everything less than 6 months ago.  We can use the Date Range aggregation to do that.  This is specifically for dates, and we can set the format of the date we want returned in the result, and use Elasticsearch's Date Math to set up our ranges.  Please see the link in the video description to read more about Date Math, but here are a few examples.  I'm setting the first to be everything before now minus 12 months, the second to be from now minus 12 months to now minus 6 months, and the third to be everything after now minus 6 months.  And you can see the counts in the results, as well as the ranges created by the Date Math.

link to https://www.elastic.co/guide/en/elasticsearch/reference/current/common-options.html#date-math in video description.

Well, that concluded our last base chapter of the series.  In this chapter, we learned about Stats and Value Count Metrics Aggregations, as well as Terms, Histograms, Range, and Date Range Bucket Aggregations.  We also learned how to omit results from our query to get our aggregations back with a faster response time.

While this is the end of the base series, please check back soon as I will be adding more specialized bonus chapters in the near future.  Some topics include Suggester fields and queries, Geolocation fields and queries, advanced aggregations such as subaggregations, and maybe even some more complex queries.  Stay tuned!

Thank you all for sticking with me through the Siteworx Elasticsearch Developer Focus Series.  It has truly been a great accomplishment for me to make these videos and if they help even one person better understand Elasticsearch, it will have all been worth it.  See you in the bonus chapters!  This is Jim, have a great day.